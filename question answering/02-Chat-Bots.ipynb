{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling, read-binary\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the train data contains 10,000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'to',\n",
       "  'the',\n",
       "  'office',\n",
       "  '.'],\n",
       " ['Is', 'Mary', 'in', 'the', 'bathroom', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story:\n",
      "Daniel grabbed the apple there.\n",
      "Daniel went to the bedroom.\n",
      "John moved to the garden.\n",
      "Sandra journeyed to the office.\n",
      "Daniel put down the apple.\n",
      "Mary went to the bedroom.\n",
      "Mary grabbed the apple there.\n",
      "Sandra went back to the garden.\n",
      "Mary went to the kitchen.\n",
      "Daniel went to the office.\n",
      "\n",
      "Question: Is Mary in the garden?\n",
      "\n",
      "Answer: no\n"
     ]
    }
   ],
   "source": [
    "text=''\n",
    "print('Story:')\n",
    "for sent in train_data[99]:\n",
    "    if sent!='yes' and sent!='no':\n",
    "        for word in sent:\n",
    "            if (word!='.'):\n",
    "                if (word!='?'):\n",
    "                    text+= word + ' '\n",
    "                else:\n",
    "                    print()\n",
    "                    print('Question:', text[:-1]+word)\n",
    "                    print()\n",
    "            else:\n",
    "                print(text[:-1]+word)\n",
    "                text=''\n",
    "    else:\n",
    "        print('Answer:', sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- list of tuples\n",
    "    - tuple contains: story x, question q and answer a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'journeyed',\n",
       " 'moved',\n",
       " 'the',\n",
       " 'to'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data[0][0]) # story component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'there': 1,\n",
       " 'is': 2,\n",
       " 'in': 3,\n",
       " 'bathroom': 4,\n",
       " 'back': 5,\n",
       " 'discarded': 6,\n",
       " 'sandra': 7,\n",
       " 'bedroom': 8,\n",
       " 'milk': 9,\n",
       " 'hallway': 10,\n",
       " 'no': 11,\n",
       " 'moved': 12,\n",
       " 'to': 13,\n",
       " 'dropped': 14,\n",
       " 'picked': 15,\n",
       " 'took': 16,\n",
       " 'left': 17,\n",
       " 'football': 18,\n",
       " 'grabbed': 19,\n",
       " 'john': 20,\n",
       " 'down': 21,\n",
       " 'got': 22,\n",
       " '?': 23,\n",
       " 'journeyed': 24,\n",
       " 'office': 25,\n",
       " 'mary': 26,\n",
       " 'the': 27,\n",
       " '.': 28,\n",
       " 'kitchen': 29,\n",
       " 'put': 30,\n",
       " 'up': 31,\n",
       " 'travelled': 32,\n",
       " 'yes': 33,\n",
       " 'daniel': 34,\n",
       " 'went': 35,\n",
       " 'garden': 36,\n",
       " 'apple': 37}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'there': 1,\n",
       " 'is': 2,\n",
       " 'in': 3,\n",
       " 'bathroom': 4,\n",
       " 'back': 5,\n",
       " 'discarded': 6,\n",
       " 'sandra': 7,\n",
       " 'bedroom': 8,\n",
       " 'milk': 9,\n",
       " 'hallway': 10,\n",
       " 'no': 11,\n",
       " 'moved': 12,\n",
       " 'to': 13,\n",
       " 'dropped': 14,\n",
       " 'picked': 15,\n",
       " 'took': 16,\n",
       " 'left': 17,\n",
       " 'football': 18,\n",
       " 'grabbed': 19,\n",
       " 'john': 20,\n",
       " 'down': 21,\n",
       " 'got': 22,\n",
       " '?': 23,\n",
       " 'journeyed': 24,\n",
       " 'office': 25,\n",
       " 'mary': 26,\n",
       " 'the': 27,\n",
       " '.': 28,\n",
       " 'kitchen': 29,\n",
       " 'put': 30,\n",
       " 'up': 31,\n",
       " 'travelled': 32,\n",
       " 'yes': 33,\n",
       " 'daniel': 34,\n",
       " 'went': 35,\n",
       " 'garden': 36,\n",
       " 'apple': 37}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    X = []\n",
    "    Xq = []\n",
    "    Y = []\n",
    "    for story, query, answer in data:   \n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]  \n",
    "        y = np.zeros(vocab_size)  \n",
    "        y[word_index[answer]] = 1\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 27,  8, 28],\n",
       "       [ 0,  0,  0, ..., 27, 36, 28],\n",
       "       [ 0,  0,  0, ..., 27, 36, 28],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 27, 37, 28],\n",
       "       [ 0,  0,  0, ..., 27, 36, 28],\n",
       "       [ 0,  0,  0, ..., 37,  1, 28]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 20,  3, 27, 29, 23],\n",
       "       [ 2, 20,  3, 27, 29, 23],\n",
       "       [ 2, 20,  3, 27, 36, 23],\n",
       "       ...,\n",
       "       [ 2, 26,  3, 27,  8, 23],\n",
       "       [ 2,  7,  3, 27, 36, 23],\n",
       "       [ 2, 26,  3, 27, 36, 23]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       497.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from tensorflow.keras.layers import add, dot, concatenate\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim= embedding_dim))\n",
    "input_encoder_m.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embedding_dim,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match, input_encoded_c])  \n",
    "response = Permute((2, 1))(response)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 284) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "model = Model([input_sequence, question], answer)\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 128)    4864        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 6, 128)       4864        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 284)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           40576       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 51,786\n",
      "Trainable params: 51,786\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "epochs = 120\n",
    "decay = initial_learning_rate / epochs\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.5\n",
    "    epochs_drop = 20\n",
    "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
    "\n",
    "learning_rate = LearningRateScheduler(lr_step_decay, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.66, patience=5, min_lr=0.0001, verbose=1)  # factor by which the learning rate will be reduced. new_lr = lr * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "40/40 [==============================] - 7s 113ms/step - loss: 0.9289 - accuracy: 0.4887 - val_loss: 0.7173 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "40/40 [==============================] - 4s 102ms/step - loss: 0.7105 - accuracy: 0.4958 - val_loss: 0.7253 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "40/40 [==============================] - 4s 103ms/step - loss: 0.7008 - accuracy: 0.5110 - val_loss: 0.8422 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.7053 - accuracy: 0.4933 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "40/40 [==============================] - 5s 119ms/step - loss: 0.6982 - accuracy: 0.4992 - val_loss: 0.7147 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "40/40 [==============================] - 5s 128ms/step - loss: 0.6980 - accuracy: 0.5019 - val_loss: 0.7108 - val_accuracy: 0.4970\n",
      "Epoch 7/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.6611 - accuracy: 0.5813 - val_loss: 0.5195 - val_accuracy: 0.7560\n",
      "Epoch 8/120\n",
      "40/40 [==============================] - 5s 117ms/step - loss: 0.4719 - accuracy: 0.7889 - val_loss: 0.5935 - val_accuracy: 0.7100\n",
      "Epoch 9/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.4024 - accuracy: 0.8299 - val_loss: 0.3939 - val_accuracy: 0.8240\n",
      "Epoch 10/120\n",
      "40/40 [==============================] - 5s 117ms/step - loss: 0.3704 - accuracy: 0.8477 - val_loss: 0.4200 - val_accuracy: 0.8090\n",
      "Epoch 11/120\n",
      "40/40 [==============================] - 5s 119ms/step - loss: 0.3514 - accuracy: 0.8472 - val_loss: 0.3881 - val_accuracy: 0.8440\n",
      "Epoch 12/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.3466 - accuracy: 0.8484 - val_loss: 0.4079 - val_accuracy: 0.8340\n",
      "Epoch 13/120\n",
      "40/40 [==============================] - 5s 116ms/step - loss: 0.3327 - accuracy: 0.8521 - val_loss: 0.4394 - val_accuracy: 0.8300\n",
      "Epoch 14/120\n",
      "40/40 [==============================] - 5s 117ms/step - loss: 0.3253 - accuracy: 0.8574 - val_loss: 0.3705 - val_accuracy: 0.8320\n",
      "Epoch 15/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.3198 - accuracy: 0.8553 - val_loss: 0.3787 - val_accuracy: 0.8220\n",
      "Epoch 16/120\n",
      "40/40 [==============================] - 5s 131ms/step - loss: 0.3133 - accuracy: 0.8596 - val_loss: 0.3706 - val_accuracy: 0.8120\n",
      "Epoch 17/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.3058 - accuracy: 0.8636 - val_loss: 0.3631 - val_accuracy: 0.8440\n",
      "Epoch 18/120\n",
      "40/40 [==============================] - 5s 119ms/step - loss: 0.3073 - accuracy: 0.8599 - val_loss: 0.3476 - val_accuracy: 0.8280\n",
      "Epoch 19/120\n",
      "40/40 [==============================] - 5s 115ms/step - loss: 0.2964 - accuracy: 0.8625 - val_loss: 0.3575 - val_accuracy: 0.8360\n",
      "Epoch 20/120\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.2970 - accuracy: 0.8649 - val_loss: 0.3789 - val_accuracy: 0.8390\n",
      "Epoch 21/120\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.2947 - accuracy: 0.8652 - val_loss: 0.3825 - val_accuracy: 0.8350\n",
      "Epoch 22/120\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.2895 - accuracy: 0.8702 - val_loss: 0.3638 - val_accuracy: 0.8150\n",
      "Epoch 23/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2915 - accuracy: 0.8674 - val_loss: 0.3770 - val_accuracy: 0.8270\n",
      "Epoch 24/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2845 - accuracy: 0.8699 - val_loss: 0.3538 - val_accuracy: 0.8430\n",
      "Epoch 25/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2835 - accuracy: 0.8688 - val_loss: 0.3929 - val_accuracy: 0.8390\n",
      "Epoch 26/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2799 - accuracy: 0.8744 - val_loss: 0.4435 - val_accuracy: 0.7960\n",
      "Epoch 27/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2833 - accuracy: 0.8708 - val_loss: 0.4210 - val_accuracy: 0.8250\n",
      "Epoch 28/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2695 - accuracy: 0.8779 - val_loss: 0.3672 - val_accuracy: 0.8310\n",
      "Epoch 29/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2710 - accuracy: 0.8742 - val_loss: 0.3750 - val_accuracy: 0.8370\n",
      "Epoch 30/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2661 - accuracy: 0.8768 - val_loss: 0.4665 - val_accuracy: 0.8290\n",
      "Epoch 31/120\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.2628 - accuracy: 0.8780 - val_loss: 0.4987 - val_accuracy: 0.7920\n",
      "Epoch 32/120\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.2634 - accuracy: 0.8778 - val_loss: 0.4020 - val_accuracy: 0.8300\n",
      "Epoch 33/120\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.2580 - accuracy: 0.8769 - val_loss: 0.4323 - val_accuracy: 0.8320\n",
      "Epoch 34/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2570 - accuracy: 0.8812 - val_loss: 0.4486 - val_accuracy: 0.7950\n",
      "Epoch 35/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2513 - accuracy: 0.8847 - val_loss: 0.5313 - val_accuracy: 0.8120\n",
      "Epoch 36/120\n",
      "40/40 [==============================] - 5s 114ms/step - loss: 0.2449 - accuracy: 0.8885 - val_loss: 0.4510 - val_accuracy: 0.8260\n",
      "Epoch 37/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2485 - accuracy: 0.8842 - val_loss: 0.4560 - val_accuracy: 0.8170\n",
      "Epoch 38/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2441 - accuracy: 0.8861 - val_loss: 0.4010 - val_accuracy: 0.8260\n",
      "Epoch 39/120\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.2376 - accuracy: 0.8893 - val_loss: 0.4347 - val_accuracy: 0.8310\n",
      "Epoch 40/120\n",
      "40/40 [==============================] - 5s 113ms/step - loss: 0.2319 - accuracy: 0.8927 - val_loss: 0.4629 - val_accuracy: 0.8250\n",
      "Epoch 41/120\n",
      "40/40 [==============================] - 5s 138ms/step - loss: 0.2299 - accuracy: 0.8925 - val_loss: 0.4727 - val_accuracy: 0.8310\n",
      "Epoch 42/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.2269 - accuracy: 0.8958 - val_loss: 0.4675 - val_accuracy: 0.8050\n",
      "Epoch 43/120\n",
      "40/40 [==============================] - 5s 133ms/step - loss: 0.2234 - accuracy: 0.8935 - val_loss: 0.4732 - val_accuracy: 0.8340\n",
      "Epoch 44/120\n",
      "40/40 [==============================] - 5s 129ms/step - loss: 0.2165 - accuracy: 0.9039 - val_loss: 0.4249 - val_accuracy: 0.8380\n",
      "Epoch 45/120\n",
      "40/40 [==============================] - 5s 129ms/step - loss: 0.2100 - accuracy: 0.9055 - val_loss: 0.5936 - val_accuracy: 0.8340\n",
      "Epoch 46/120\n",
      "40/40 [==============================] - 5s 121ms/step - loss: 0.2069 - accuracy: 0.9058 - val_loss: 0.4580 - val_accuracy: 0.8350\n",
      "Epoch 47/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1943 - accuracy: 0.9129 - val_loss: 0.4542 - val_accuracy: 0.8420\n",
      "Epoch 48/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1916 - accuracy: 0.9157 - val_loss: 0.4139 - val_accuracy: 0.8450\n",
      "Epoch 49/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1793 - accuracy: 0.9191 - val_loss: 0.4307 - val_accuracy: 0.8450\n",
      "Epoch 50/120\n",
      "40/40 [==============================] - 5s 120ms/step - loss: 0.1722 - accuracy: 0.9256 - val_loss: 0.4827 - val_accuracy: 0.8590\n",
      "Epoch 51/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1679 - accuracy: 0.9266 - val_loss: 0.4188 - val_accuracy: 0.8560\n",
      "Epoch 52/120\n",
      "40/40 [==============================] - 5s 117ms/step - loss: 0.1543 - accuracy: 0.9325 - val_loss: 0.4641 - val_accuracy: 0.8590\n",
      "Epoch 53/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1559 - accuracy: 0.9322 - val_loss: 0.3935 - val_accuracy: 0.8550\n",
      "Epoch 54/120\n",
      "40/40 [==============================] - 5s 120ms/step - loss: 0.1508 - accuracy: 0.9351 - val_loss: 0.4133 - val_accuracy: 0.8400\n",
      "Epoch 55/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1422 - accuracy: 0.9410 - val_loss: 0.3391 - val_accuracy: 0.8610\n",
      "Epoch 56/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1321 - accuracy: 0.9448 - val_loss: 0.3475 - val_accuracy: 0.8790\n",
      "Epoch 57/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1326 - accuracy: 0.9428 - val_loss: 0.4483 - val_accuracy: 0.8430\n",
      "Epoch 58/120\n",
      "40/40 [==============================] - 5s 117ms/step - loss: 0.1304 - accuracy: 0.9451 - val_loss: 0.4259 - val_accuracy: 0.8800\n",
      "Epoch 59/120\n",
      "40/40 [==============================] - 5s 119ms/step - loss: 0.1283 - accuracy: 0.9460 - val_loss: 0.3785 - val_accuracy: 0.8750\n",
      "Epoch 60/120\n",
      "40/40 [==============================] - 5s 121ms/step - loss: 0.1205 - accuracy: 0.9504 - val_loss: 0.4342 - val_accuracy: 0.8810\n",
      "Epoch 61/120\n",
      "40/40 [==============================] - 5s 119ms/step - loss: 0.1162 - accuracy: 0.9505 - val_loss: 0.3395 - val_accuracy: 0.8840\n",
      "Epoch 62/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1134 - accuracy: 0.9550 - val_loss: 0.3462 - val_accuracy: 0.8800\n",
      "Epoch 63/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1069 - accuracy: 0.9539 - val_loss: 0.4109 - val_accuracy: 0.8850\n",
      "Epoch 64/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1043 - accuracy: 0.9539 - val_loss: 0.3640 - val_accuracy: 0.8900\n",
      "Epoch 65/120\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.1017 - accuracy: 0.9578 - val_loss: 0.5359 - val_accuracy: 0.8820\n",
      "Epoch 66/120\n",
      "40/40 [==============================] - 5s 120ms/step - loss: 0.1008 - accuracy: 0.9580 - val_loss: 0.4977 - val_accuracy: 0.8590\n",
      "Epoch 67/120\n",
      "40/40 [==============================] - 5s 120ms/step - loss: 0.1019 - accuracy: 0.9600 - val_loss: 0.3422 - val_accuracy: 0.8910\n",
      "Epoch 68/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.0948 - accuracy: 0.9624 - val_loss: 0.3800 - val_accuracy: 0.8800\n",
      "Epoch 69/120\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.0951 - accuracy: 0.9601 - val_loss: 0.3477 - val_accuracy: 0.8880\n",
      "Epoch 70/120\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.0888 - accuracy: 0.9647 - val_loss: 0.4071 - val_accuracy: 0.8780\n",
      "Epoch 71/120\n",
      "40/40 [==============================] - 5s 120ms/step - loss: 0.0891 - accuracy: 0.9654 - val_loss: 0.3742 - val_accuracy: 0.8770\n",
      "Epoch 72/120\n",
      "40/40 [==============================] - 5s 121ms/step - loss: 0.0924 - accuracy: 0.9610 - val_loss: 0.4242 - val_accuracy: 0.8720\n",
      "Epoch 73/120\n",
      "40/40 [==============================] - 5s 121ms/step - loss: 0.0864 - accuracy: 0.9637 - val_loss: 0.3834 - val_accuracy: 0.8760\n",
      "Epoch 74/120\n",
      "40/40 [==============================] - 5s 121ms/step - loss: 0.0788 - accuracy: 0.9688 - val_loss: 0.4354 - val_accuracy: 0.8910\n",
      "Epoch 75/120\n",
      "40/40 [==============================] - 5s 120ms/step - loss: 0.0866 - accuracy: 0.9672 - val_loss: 0.3549 - val_accuracy: 0.8920\n",
      "Epoch 76/120\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.0763 - accuracy: 0.9685 - val_loss: 0.3463 - val_accuracy: 0.9010\n",
      "Epoch 77/120\n",
      "40/40 [==============================] - 5s 120ms/step - loss: 0.0802 - accuracy: 0.9691 - val_loss: 0.3608 - val_accuracy: 0.8970\n",
      "Epoch 78/120\n",
      "40/40 [==============================] - 5s 120ms/step - loss: 0.0803 - accuracy: 0.9696 - val_loss: 0.3812 - val_accuracy: 0.8940\n",
      "Epoch 79/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0769 - accuracy: 0.9699 - val_loss: 0.4173 - val_accuracy: 0.8800\n",
      "Epoch 80/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.0742 - accuracy: 0.9697 - val_loss: 0.4089 - val_accuracy: 0.9010\n",
      "Epoch 81/120\n",
      "40/40 [==============================] - 5s 121ms/step - loss: 0.0735 - accuracy: 0.9720 - val_loss: 0.3752 - val_accuracy: 0.9020\n",
      "Epoch 82/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0747 - accuracy: 0.9701 - val_loss: 0.4016 - val_accuracy: 0.8990\n",
      "Epoch 83/120\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.0653 - accuracy: 0.9760 - val_loss: 0.3619 - val_accuracy: 0.9000\n",
      "Epoch 84/120\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.0767 - accuracy: 0.9715 - val_loss: 0.3729 - val_accuracy: 0.9010\n",
      "Epoch 85/120\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.0674 - accuracy: 0.9753 - val_loss: 0.4032 - val_accuracy: 0.8910\n",
      "Epoch 86/120\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.0633 - accuracy: 0.9764 - val_loss: 0.4025 - val_accuracy: 0.8960\n",
      "Epoch 87/120\n",
      "40/40 [==============================] - 5s 121ms/step - loss: 0.0658 - accuracy: 0.9752 - val_loss: 0.4308 - val_accuracy: 0.8920\n",
      "Epoch 88/120\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.0617 - accuracy: 0.9759 - val_loss: 0.4138 - val_accuracy: 0.9050\n",
      "Epoch 89/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.0569 - accuracy: 0.9800 - val_loss: 0.4318 - val_accuracy: 0.8980\n",
      "Epoch 90/120\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.0649 - accuracy: 0.9759 - val_loss: 0.4338 - val_accuracy: 0.9040\n",
      "Epoch 91/120\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.0646 - accuracy: 0.9765 - val_loss: 0.3748 - val_accuracy: 0.9070\n",
      "Epoch 92/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.0583 - accuracy: 0.9767 - val_loss: 0.4259 - val_accuracy: 0.8910\n",
      "Epoch 93/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.0579 - accuracy: 0.9799 - val_loss: 0.4288 - val_accuracy: 0.9040\n",
      "Epoch 94/120\n",
      "40/40 [==============================] - 5s 129ms/step - loss: 0.0590 - accuracy: 0.9785 - val_loss: 0.4426 - val_accuracy: 0.8970\n",
      "Epoch 95/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.0557 - accuracy: 0.9787 - val_loss: 0.3486 - val_accuracy: 0.9020\n",
      "Epoch 96/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.0561 - accuracy: 0.9787 - val_loss: 0.4540 - val_accuracy: 0.9020\n",
      "Epoch 97/120\n",
      "40/40 [==============================] - 5s 122ms/step - loss: 0.0549 - accuracy: 0.9802 - val_loss: 0.4150 - val_accuracy: 0.9090\n",
      "Epoch 98/120\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.0519 - accuracy: 0.9803 - val_loss: 0.4814 - val_accuracy: 0.8960\n",
      "Epoch 99/120\n",
      "40/40 [==============================] - 5s 128ms/step - loss: 0.0537 - accuracy: 0.9811 - val_loss: 0.4002 - val_accuracy: 0.9130\n",
      "Epoch 100/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0595 - accuracy: 0.9799 - val_loss: 0.3957 - val_accuracy: 0.9000\n",
      "Epoch 101/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0526 - accuracy: 0.9798 - val_loss: 0.4166 - val_accuracy: 0.9050\n",
      "Epoch 102/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0540 - accuracy: 0.9809 - val_loss: 0.4143 - val_accuracy: 0.9060\n",
      "Epoch 103/120\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.0487 - accuracy: 0.9837 - val_loss: 0.4651 - val_accuracy: 0.9030\n",
      "Epoch 104/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0455 - accuracy: 0.9836 - val_loss: 0.4352 - val_accuracy: 0.9080\n",
      "Epoch 105/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0498 - accuracy: 0.9820 - val_loss: 0.4237 - val_accuracy: 0.9070\n",
      "Epoch 106/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0440 - accuracy: 0.9833 - val_loss: 0.4302 - val_accuracy: 0.9060\n",
      "Epoch 107/120\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.0494 - accuracy: 0.9834 - val_loss: 0.4157 - val_accuracy: 0.9030\n",
      "Epoch 108/120\n",
      "40/40 [==============================] - 5s 129ms/step - loss: 0.0421 - accuracy: 0.9843 - val_loss: 0.4187 - val_accuracy: 0.9090\n",
      "Epoch 109/120\n",
      "40/40 [==============================] - 5s 128ms/step - loss: 0.0402 - accuracy: 0.9865 - val_loss: 0.5130 - val_accuracy: 0.9030\n",
      "Epoch 110/120\n",
      "40/40 [==============================] - 5s 131ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.4158 - val_accuracy: 0.8950\n",
      "Epoch 111/120\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.0428 - accuracy: 0.9848 - val_loss: 0.4048 - val_accuracy: 0.9060\n",
      "Epoch 112/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0595 - accuracy: 0.9820 - val_loss: 0.4268 - val_accuracy: 0.9050\n",
      "Epoch 113/120\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.0466 - accuracy: 0.9835 - val_loss: 0.4513 - val_accuracy: 0.8990\n",
      "Epoch 114/120\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.0411 - accuracy: 0.9857 - val_loss: 0.4506 - val_accuracy: 0.9120\n",
      "Epoch 115/120\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.0450 - accuracy: 0.9843 - val_loss: 0.4206 - val_accuracy: 0.9100\n",
      "Epoch 116/120\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.0421 - accuracy: 0.9835 - val_loss: 0.4430 - val_accuracy: 0.9150\n",
      "Epoch 117/120\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.0433 - accuracy: 0.9849 - val_loss: 0.3966 - val_accuracy: 0.9130\n",
      "Epoch 118/120\n",
      "40/40 [==============================] - 5s 133ms/step - loss: 0.0507 - accuracy: 0.9824 - val_loss: 0.4461 - val_accuracy: 0.9100\n",
      "Epoch 119/120\n",
      "40/40 [==============================] - 5s 127ms/step - loss: 0.0418 - accuracy: 0.9850 - val_loss: 0.4219 - val_accuracy: 0.9050\n",
      "Epoch 120/120\n",
      "40/40 [==============================] - 5s 128ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 0.4106 - val_accuracy: 0.9090\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=256,epochs=120,validation_data=([inputs_test, queries_test], answers_test))  # , callbacks=[reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hiten_t0xw2z5\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "filename = 'QandA.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"word_dict.pkl\", 'wb') as f:\n",
    "    pickle.dump(word_index, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('accuracy.png', dpi=180, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  1.0\n"
     ]
    }
   ],
   "source": [
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
